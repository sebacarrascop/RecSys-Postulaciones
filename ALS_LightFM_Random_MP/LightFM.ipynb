{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQTohgJkLd8s"
      },
      "source": [
        "# Implementación LightFM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csKptpk2WV_B"
      },
      "source": [
        "## Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "81WTQ_adWaSo"
      },
      "outputs": [],
      "source": [
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset\n",
        "import pandas as pd\n",
        "from lightfm.evaluation import precision_at_k, recall_at_k\n",
        "from lightfm.evaluation import auc_score\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nn_vxiCkNHof"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O1rtsnwttiAr"
      },
      "outputs": [],
      "source": [
        "df_postulantes = pd.read_csv('postulantes_procesados.csv', index_col=0)\n",
        "df_establecimientos = pd.read_csv('establecimientos_procesados.csv', index_col=0)\n",
        "df_postulaciones_training = pd.read_csv('postulaciones_training.csv', index_col=0)\n",
        "df_postulaciones_testing = pd.read_csv('postulaciones_testing.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9zJqlwHLhTdg"
      },
      "outputs": [],
      "source": [
        "for col in df_establecimientos.columns:\n",
        "  if ((col != 'LATITUD') and (col != 'LONGITUD')):\n",
        "    df_establecimientos[col] = df_establecimientos[col].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kcYYaQj8Hwgw"
      },
      "outputs": [],
      "source": [
        "df_establecimientos.drop(columns=['COD_COM_RBD', 'LATITUD', 'LONGITUD'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eWe3_ViUuIbE"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset()\n",
        "dataset.fit(\n",
        "    users=df_postulaciones_training['mrun'].unique(),\n",
        "    items=df_postulaciones_training['rbd'].unique(),\n",
        "    item_features=[col for col in df_establecimientos.columns if col != 'RBD']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MRl_BfvuqOw",
        "outputId": "0ded52d3-c624-415e-dd4e-c8812840433d"
      },
      "outputs": [],
      "source": [
        "# Construir las interacciones de entrenamiento\n",
        "(interactions, weights) = dataset.build_interactions(\n",
        "    (row['mrun'], row['rbd']) for _, row in df_postulaciones_training.iterrows()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtER_sdQu1LO",
        "outputId": "e2f90fc7-38dd-44c5-b457-367e359dac84"
      },
      "outputs": [],
      "source": [
        "# Construir las características de los ítems\n",
        "item_features = dataset.build_item_features(\n",
        "    [\n",
        "        (row['RBD'], {col: int(row[col]) for col in df_establecimientos.columns if col != 'RBD'})\n",
        "        for _, row in df_establecimientos.iterrows()\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 100/100 [08:35<00:00,  5.16s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7f8524982f20>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LightFM(loss='bpr')\n",
        "model.fit_partial(interactions, item_features=item_features, epochs=100, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "z4jtvu48l3gk"
      },
      "outputs": [],
      "source": [
        "# Construir las interacciones de prueba\n",
        "(test_interactions, test_weights) = dataset.build_interactions(\n",
        "    (row['mrun'], row['rbd']) for _, row in df_postulaciones_testing.iterrows()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "def ndcg_at_k(\n",
        "    model,\n",
        "    test_interactions,\n",
        "    train_interactions=None,\n",
        "    k=10,\n",
        "    user_features=None,\n",
        "    item_features=None,\n",
        "    preserve_rows=False,\n",
        "    num_threads=1,\n",
        "    check_intersections=True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Measure the normalized discounted cumulative gain (NDCG) at k metric for a model:\n",
        "    the DCG at k divided by the ideal DCG at k. A perfect score is 1.0.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: LightFM instance\n",
        "        the fitted model to be evaluated\n",
        "    test_interactions: np.float32 csr_matrix of shape [n_users, n_items]\n",
        "        Non-zero entries representing known positives in the evaluation set.\n",
        "    train_interactions: np.float32 csr_matrix of shape [n_users, n_items], optional\n",
        "        Non-zero entries representing known positives in the train set. These\n",
        "        will be omitted from the score calculations to avoid re-recommending\n",
        "        known positives.\n",
        "    k: integer, optional\n",
        "        The k parameter.\n",
        "    user_features: np.float32 csr_matrix of shape [n_users, n_user_features], optional\n",
        "        Each row contains that user's weights over features.\n",
        "    item_features: np.float32 csr_matrix of shape [n_items, n_item_features], optional\n",
        "        Each row contains that item's weights over features.\n",
        "    preserve_rows: boolean, optional\n",
        "        When False (default), the number of rows in the output will be equal\n",
        "        to the number of users with interactions in the evaluation set.\n",
        "        When True, the number of rows in the output will be equal to the\n",
        "        number of users.\n",
        "    num_threads: int, optional\n",
        "        Number of parallel computation threads to use. Should\n",
        "        not be higher than the number of physical cores.\n",
        "    check_intersections: bool, optional, True by default,\n",
        "        Only relevant when train_interactions are supplied.\n",
        "        A flag that signals whether the test and train matrices should be checked\n",
        "        for intersections to prevent optimistic ranks / wrong evaluation / bad data split.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.array of shape [n_users with interactions or n_users,]\n",
        "        Numpy array containing NDCG@k scores for each user.\n",
        "        If there are no interactions for a given user the returned value will be 0.0.\n",
        "    \"\"\"\n",
        "\n",
        "    if num_threads < 1:\n",
        "        raise ValueError(\"Number of threads must be 1 or larger.\")\n",
        "\n",
        "    ranks = model.predict_rank(\n",
        "        test_interactions,\n",
        "        train_interactions=train_interactions,\n",
        "        user_features=user_features,\n",
        "        item_features=item_features,\n",
        "        num_threads=num_threads,\n",
        "        check_intersections=check_intersections,\n",
        "    )\n",
        "\n",
        "    # Only consider the top k predictions\n",
        "    ranks.data = np.less(ranks.data, k, ranks.data)\n",
        "\n",
        "    ndcg_scores = []\n",
        "\n",
        "    test_interactions = test_interactions.tocsr()\n",
        "    ranks = ranks.tocsr()\n",
        "\n",
        "    for user_id in range(test_interactions.shape[0]):\n",
        "        user_test_interactions = test_interactions[user_id].toarray().flatten()\n",
        "        if user_test_interactions.sum() == 0:\n",
        "            ndcg_scores.append(0.0)\n",
        "            continue\n",
        "\n",
        "        user_ranks = ranks[user_id].data\n",
        "\n",
        "        # Consider only the top k ranks\n",
        "        top_k_indices = np.argsort(user_ranks)[:k]\n",
        "        user_ranks_top_k = user_ranks[top_k_indices]\n",
        "        user_test_interactions_top_k = user_test_interactions[top_k_indices]\n",
        "\n",
        "        # Discounted cumulative gain at k\n",
        "        dcg = np.sum((1 / np.log2(np.arange(1, len(user_ranks_top_k) + 1) + 1)) * user_test_interactions_top_k)\n",
        "\n",
        "        # Ideal discounted cumulative gain at k\n",
        "        ideal_ranks = np.sort(user_test_interactions)[::-1][:k]\n",
        "        idcg = np.sum((1 / np.log2(np.arange(1, len(ideal_ranks) + 1) + 1)) * ideal_ranks)\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        ndcg_scores.append(ndcg)\n",
        "\n",
        "    return np.mean(ndcg_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVCe1sXhnu6p",
        "outputId": "ee42b9af-72c9-41ec-ca56-64535eb87807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.0163789019.\n",
            "AUC: 0.8010588288.\n",
            "Recall: 0.2137884586.\n",
            "NDCG: 0.0020882798.\n"
          ]
        }
      ],
      "source": [
        "# Evaluar el modelo\n",
        "test_precision = precision_at_k(model=model, test_interactions=test_interactions, item_features=item_features, k=20, train_interactions=interactions).mean()\n",
        "\n",
        "test_auc = auc_score(model=model, test_interactions=test_interactions, item_features=item_features, train_interactions=interactions).mean()\n",
        "\n",
        "test_recall = recall_at_k(model=model, test_interactions=test_interactions, item_features=item_features, k=20, train_interactions=interactions).mean()\n",
        "\n",
        "test_ndcg = ndcg_at_k(model=model, test_interactions=test_interactions, item_features=item_features, k=20, train_interactions=interactions)\n",
        "\n",
        "print('Precision: %.10f.' % (test_precision))\n",
        "print('AUC: %.10f.' % (test_auc))\n",
        "print('Recall: %.10f.' % (test_recall))\n",
        "print('NDCG: %.10f.' % (test_ndcg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "predicciones_lightfm = {}\n",
        "lista_id_usuarios = list(dataset.mapping()[0].keys())\n",
        "lista_id_establecimientos = list(dataset.mapping()[2].keys())\n",
        "\n",
        "establecimientos_random = df_postulaciones_testing.sample(n=10)\n",
        "\n",
        "for _,usuario in establecimientos_random.iterrows():\n",
        "    (test_interactions, test_weights) = dataset.build_interactions(\n",
        "        (usuario['mrun'], establecimiento) for establecimiento in df_establecimientos['RBD']\n",
        "    )\n",
        "    ranks = model.predict_rank(test_interactions, item_features=item_features)\n",
        "    non_zero_values = ranks.data\n",
        "    row_indices, col_indices = ranks.nonzero()\n",
        "\n",
        "    non_zero_elements = list(zip(row_indices, col_indices, non_zero_values))\n",
        "    non_zero_elements = [(int(row[2]), int(row[0]), int(row[1])) for row in non_zero_elements]\n",
        "    non_zero_elements.sort()\n",
        "    predicciones_lightfm[int(lista_id_usuarios[non_zero_elements[0][1]])] = [int(lista_id_establecimientos[non_zero_elements[i][2]]) for i in range(20)]\n",
        "\n",
        "with open('../Visualizacion/data/recomendaciones_lightfm.json', 'w') as output:\n",
        "    json.dump(predicciones_lightfm, output)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "AQ5HykA-Gh6w",
        "4bve9AjFtRw4",
        "Tt0sUNoBo0BP"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
